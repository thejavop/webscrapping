import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score, 
    classification_report, 
    confusion_matrix,
    precision_recall_fscore_support
)
from sklearn.model_selection import GridSearchCV, cross_val_score
import joblib
import warnings
import time

warnings.filterwarnings('ignore')

# Importar la clase de preprocesamiento
from preprocesamiento import PreprocesadorNoticias


class ClasificadorNoticias:
    """
    Clasificador de noticias usando TF-IDF + RandomForestClassifier + LogisticRegression
    (Ejercicio 3 - RA4)
    
    Compara dos modelos:
    - Random Forest (√°rbol de decisiones m√∫ltiple)
    - Logistic Regression (modelo lineal)
    """

    def __init__(self):  # ‚úÖ CORREGIDO: doble gui√≥n bajo
        """Inicializa el clasificador"""
        self.modelo = None
        self.mejor_modelo = None
        self.modelo_logistic = None
        self.preprocessor = None
        self.categorias = None
        self.tiempo_entrenamiento = {}  # Diccionario para almacenar tiempos
        self.metricas_todas = {}  # Para almacenar todas las m√©tricas

    # ------------------------------------------------------------------
    # CARGA Y PREPROCESAMIENTO
    # ------------------------------------------------------------------
    def cargar_datos_preprocesados(self):
        """Carga el CSV y ejecuta el pipeline de preprocesamiento"""
        print("="*80)
        print("üîÑ CARGANDO Y PREPROCESANDO DATOS")
        print("="*80)

        self.preprocessor = PreprocesadorNoticias('abc_news.csv')
        self.preprocessor.ejecutar_pipeline_completo()

        self.X_train = self.preprocessor.X_train
        self.X_test = self.preprocessor.X_test
        self.y_train = self.preprocessor.y_train
        self.y_test = self.preprocessor.y_test

        self.categorias = sorted(np.unique(self.y_train))

        print("\n‚úÖ Datos cargados correctamente")
        print(f"   - Categor√≠as: {self.categorias}")

    # ------------------------------------------------------------------
    # ENTRENAMIENTO
    # ------------------------------------------------------------------
    def entrenar_modelo_base(self):
        """Entrena Random Forest con par√°metros por defecto"""
        print("\n" + "="*80)
        print("üå≤ ENTRENANDO RANDOM FOREST (MODELO BASE)")
        print("="*80)
        print("Par√°metros: n_estimators=100, random_state=42")

        self.modelo = RandomForestClassifier(
            n_estimators=100,
            random_state=42,
            n_jobs=-1,  # Usa todos los cores del CPU
            verbose=0
        )

        print("\n‚è≥ Entrenando...")
        inicio = time.time()
        self.modelo.fit(self.X_train, self.y_train)
        tiempo = time.time() - inicio
        self.tiempo_entrenamiento['rf_base'] = tiempo

        print(f"‚úÖ Random Forest entrenado en {tiempo:.2f} segundos")

    def entrenar_logistic_regression(self):
        """Entrena Logistic Regression para comparar"""
        print("\n" + "="*80)
        print("üìä ENTRENANDO LOGISTIC REGRESSION (COMPARACI√ìN)")
        print("="*80)
        print("Par√°metros: max_iter=1000, solver='lbfgs'")

        self.modelo_logistic = LogisticRegression(
            max_iter=1000,
            random_state=42,
            solver='lbfgs',
            verbose=0
        )

        print("\n‚è≥ Entrenando...")
        inicio = time.time()
        self.modelo_logistic.fit(self.X_train, self.y_train)
        tiempo = time.time() - inicio
        self.tiempo_entrenamiento['logistic'] = tiempo

        print(f"‚úÖ Logistic Regression entrenado en {tiempo:.2f} segundos")

    # ------------------------------------------------------------------
    # EVALUACI√ìN
    # ------------------------------------------------------------------
    def evaluar_modelo(self, modelo, nombre):
        """Eval√∫a el modelo y retorna m√©tricas completas"""
        print("\n" + "="*80)
        print(f"üìä EVALUANDO {nombre.upper()}")
        print("="*80)

        # Predicciones
        y_pred_train = modelo.predict(self.X_train)
        y_pred_test = modelo.predict(self.X_test)

        # Accuracy
        train_acc = accuracy_score(self.y_train, y_pred_train)
        test_acc = accuracy_score(self.y_test, y_pred_test)

        print(f"\nüéØ ACCURACY:")
        print(f"   - Train: {train_acc:.4f} ({train_acc*100:.2f}%)")
        print(f"   - Test:  {test_acc:.4f} ({test_acc*100:.2f}%)")

        # Reporte de clasificaci√≥n
        print(f"\nüìã REPORTE DE CLASIFICACI√ìN (Test):")
        print("-"*80)
        print(classification_report(
            self.y_test, 
            y_pred_test, 
            target_names=self.categorias,
            digits=4
        ))

        # Matriz de confusi√≥n
        cm = confusion_matrix(self.y_test, y_pred_test, labels=self.categorias)

        # M√©tricas promedio
        precision, recall, f1, _ = precision_recall_fscore_support(
            self.y_test, 
            y_pred_test, 
            average='weighted'
        )

        # Tiempo de entrenamiento
        tiempo_key = None
        if 'Random Forest Base' in nombre:
            tiempo_key = 'rf_base'
        elif 'Logistic' in nombre:
            tiempo_key = 'logistic'
        elif 'Optimizado' in nombre:
            tiempo_key = 'rf_optimizado'

        tiempo = self.tiempo_entrenamiento.get(tiempo_key, 0)

        print(f"\n‚è±Ô∏è  Tiempo de entrenamiento: {tiempo:.2f} segundos")

        metricas = {
            'nombre': nombre,
            'train_accuracy': train_acc,
            'test_accuracy': test_acc,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'confusion_matrix': cm,
            'y_pred_test': y_pred_test,
            'tiempo_entrenamiento': tiempo
        }

        # Guardar en diccionario global
        self.metricas_todas[nombre] = metricas

        return metricas

    # ------------------------------------------------------------------
    # OPTIMIZACI√ìN
    # ------------------------------------------------------------------
    def optimizar_hiperparametros_randomforest(self):
        """Optimiza hiperpar√°metros de Random Forest con GridSearchCV"""
        print("\n" + "="*80)
        print("üîß OPTIMIZANDO RANDOM FOREST CON GRIDSEARCHCV")
        print("="*80)

        param_grid = {
            'n_estimators': [100, 200],
            'max_depth': [None, 30],
            'min_samples_split': [2, 5]
        }

        print("\nüîç Par√°metros a probar:")
        for param, values in param_grid.items():
            print(f"   - {param}: {values}")

        total_combinaciones = np.prod([len(v) for v in param_grid.values()])
        print(f"\nüìä Total de combinaciones: {total_combinaciones}")
        print(f"‚è≥ Esto puede tardar varios minutos...")

        grid = GridSearchCV(
            RandomForestClassifier(random_state=42, n_jobs=-1),
            param_grid,
            cv=3,  # 3-fold cross-validation
            scoring='accuracy',
            n_jobs=-1,
            verbose=1
        )

        inicio = time.time()
        grid.fit(self.X_train, self.y_train)
        tiempo = time.time() - inicio
        self.tiempo_entrenamiento['rf_optimizado'] = tiempo

        self.mejor_modelo = grid.best_estimator_

        print(f"\n‚úÖ Optimizaci√≥n completada en {tiempo:.2f} segundos")
        print(f"\nüèÜ MEJORES HIPERPAR√ÅMETROS:")
        for param, value in grid.best_params_.items():
            print(f"   - {param}: {value}")
        print(f"\nüìä Mejor Score (CV): {grid.best_score_:.4f}")

        return self.mejor_modelo

    # ------------------------------------------------------------------
    # VISUALIZACIONES
    # ------------------------------------------------------------------
    def visualizar_matriz_confusion(self, metricas, guardar=True):
        """Genera heatmap de la matriz de confusi√≥n"""
        plt.figure(figsize=(10, 8))
        
        sns.heatmap(
            metricas['confusion_matrix'],
            annot=True,
            fmt='d',
            cmap='Blues',
            xticklabels=self.categorias,
            yticklabels=self.categorias,
            cbar_kws={'label': 'N√∫mero de predicciones'}
        )
        
        plt.title(
            f"Matriz de Confusi√≥n - {metricas['nombre']}\n"
            f"Accuracy: {metricas['test_accuracy']:.4f}",
            fontsize=14,
            fontweight='bold',
            pad=20
        )
        plt.ylabel('Categor√≠a Real', fontsize=12, fontweight='bold')
        plt.xlabel('Categor√≠a Predicha', fontsize=12, fontweight='bold')
        plt.tight_layout()
        
        if guardar:
            filename = f"matriz_confusion_{metricas['nombre'].lower().replace(' ', '_')}.png"
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            print(f"   ‚úÖ Guardado: {filename}")
        
        plt.close()

    def comparar_modelos_tabla(self):
        """Genera tabla comparativa de todos los modelos"""
        print("\n" + "="*80)
        print("üìä TABLA COMPARATIVA DE MODELOS")
        print("="*80)

        # Crear DataFrame con las m√©tricas
        datos_tabla = []
        for nombre, metricas in self.metricas_todas.items():
            datos_tabla.append({
                'Modelo': nombre,
                'Train Acc': f"{metricas['train_accuracy']:.4f}",
                'Test Acc': f"{metricas['test_accuracy']:.4f}",
                'Precision': f"{metricas['precision']:.4f}",
                'Recall': f"{metricas['recall']:.4f}",
                'F1-Score': f"{metricas['f1_score']:.4f}",
                'Tiempo (s)': f"{metricas['tiempo_entrenamiento']:.2f}"
            })

        df_comparacion = pd.DataFrame(datos_tabla)
        print("\n" + df_comparacion.to_string(index=False))

        # Guardar como CSV
        df_comparacion.to_csv('comparacion_modelos.csv', index=False)
        print("\nüíæ Tabla guardada en: comparacion_modelos.csv")

    def visualizar_comparacion_accuracy(self, guardar=True):
        """Gr√°fico de barras comparando accuracy de los modelos"""
        modelos = list(self.metricas_todas.keys())
        test_accs = [m['test_accuracy'] for m in self.metricas_todas.values()]

        plt.figure(figsize=(12, 6))
        
        colores = ['steelblue', 'darkorange', 'green']
        bars = plt.bar(modelos, test_accs, color=colores[:len(modelos)], edgecolor='black')

        # A√±adir valores sobre las barras
        for bar in bars:
            height = bar.get_height()
            plt.text(
                bar.get_x() + bar.get_width()/2.,
                height,
                f'{height:.4f}',
                ha='center',
                va='bottom',
                fontsize=11,
                fontweight='bold'
            )

        plt.xlabel('Modelo', fontsize=12, fontweight='bold')
        plt.ylabel('Test Accuracy', fontsize=12, fontweight='bold')
        plt.title('Comparaci√≥n de Accuracy entre Modelos', fontsize=14, fontweight='bold', pad=20)
        plt.ylim([0, 1.1])
        plt.xticks(rotation=15, ha='right')
        plt.grid(axis='y', alpha=0.3)
        plt.tight_layout()

        if guardar:
            plt.savefig('comparacion_accuracy.png', dpi=300, bbox_inches='tight')
            print("   ‚úÖ Guardado: comparacion_accuracy.png")

        plt.close()

    # ------------------------------------------------------------------
    # GUARDAR MODELO
    # ------------------------------------------------------------------
    def guardar_modelo(self, modelo, nombre):
        """Guarda el modelo junto con el vectorizer y categor√≠as"""
        paquete = {
            'modelo': modelo,
            'vectorizer': self.preprocessor.vectorizer,
            'categorias': self.categorias
        }
        joblib.dump(paquete, nombre)
        print(f"üíæ Modelo guardado en: {nombre}")

    # ------------------------------------------------------------------
    # PIPELINE COMPLETO
    # ------------------------------------------------------------------
    def ejecutar_pipeline_completo(self):
        """Ejecuta el pipeline completo de clasificaci√≥n"""
        print("\n" + "üöÄ"*40)
        print("PIPELINE COMPLETO DE CLASIFICACI√ìN - RANDOM FOREST vs LOGISTIC REGRESSION")
        print("üöÄ"*40 + "\n")

        # 1. Cargar datos
        self.cargar_datos_preprocesados()

        # 2. Entrenar modelos base
        self.entrenar_modelo_base()
        self.entrenar_logistic_regression()

        # 3. Evaluar modelos base
        print("\n" + "üìä"*40)
        print("EVALUACI√ìN DE MODELOS BASE")
        print("üìä"*40)
        
        metricas_rf = self.evaluar_modelo(self.modelo, "Random Forest Base")
        metricas_lr = self.evaluar_modelo(self.modelo_logistic, "Logistic Regression")

        # 4. Optimizar Random Forest
        mejor_rf = self.optimizar_hiperparametros_randomforest()
        metricas_rf_opt = self.evaluar_modelo(mejor_rf, "Random Forest Optimizado")

        # 5. Generar visualizaciones
        print("\n" + "="*80)
        print("üìä GENERANDO VISUALIZACIONES")
        print("="*80)
        
        self.visualizar_matriz_confusion(metricas_rf)
        self.visualizar_matriz_confusion(metricas_lr)
        self.visualizar_matriz_confusion(metricas_rf_opt)
        self.visualizar_comparacion_accuracy()

        # 6. Tabla comparativa
        self.comparar_modelos_tabla()

        # 7. Guardar modelos
        print("\n" + "="*80)
        print("üíæ GUARDANDO MODELOS")
        print("="*80)
        self.guardar_modelo(mejor_rf, "modelo_randomforest_optimizado.pkl")
        self.guardar_modelo(self.modelo_logistic, "modelo_logistic_regression.pkl")

        # 8. Resumen final
        print("\n" + "="*80)
        print("‚úÖ PIPELINE COMPLETADO EXITOSAMENTE")
        print("="*80)
        
        print(f"\nüìÅ Archivos generados:")
        print(f"   - matriz_confusion_random_forest_base.png")
        print(f"   - matriz_confusion_logistic_regression.png")
        print(f"   - matriz_confusion_random_forest_optimizado.png")
        print(f"   - comparacion_accuracy.png")
        print(f"   - comparacion_modelos.csv")
        print(f"   - modelo_randomforest_optimizado.pkl")
        print(f"   - modelo_logistic_regression.pkl")

        # Mejor modelo
        mejor_nombre = max(self.metricas_todas.items(), 
                          key=lambda x: x[1]['test_accuracy'])[0]
        mejor_acc = self.metricas_todas[mejor_nombre]['test_accuracy']

        print(f"\nüèÜ MEJOR MODELO: {mejor_nombre}")
        print(f"   Test Accuracy: {mejor_acc:.4f} ({mejor_acc*100:.2f}%)")

        print("\n" + "üéâ"*40)
        print("¬°CLASIFICADOR DE NOTICIAS COMPLETADO!")
        print("üéâ"*40 + "\n")


# ----------------------------------------------------------------------
# MAIN
# ----------------------------------------------------------------------
if __name__ == "__main__":
    clasificador = ClasificadorNoticias()
    clasificador.ejecutar_pipeline_completo()